{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Scala Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to load [TensorFlowScala](http://platanios.org/tensorflow_scala) into our kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\n",
    "  coursier.Dependency(\n",
    "    module = coursier.Module(\"org.platanios\", \"tensorflow_2.12\"),\n",
    "    version = \"0.4.1\",\n",
    "    attributes = coursier.Attributes(\"\", \"darwin-cpu-x86_64\") // replace with linux-cpu-x86_64 or linux-gpu-x86_64 on linux\n",
    "  )\n",
    ")\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.layers._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.Paths\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.learn._\n",
    "import org.platanios.tensorflow.api.learn.layers._\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "\n",
    "import java.nio.file.Paths\n",
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 14:28:15.741 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file 'tmp/train-images-idx3-ubyte.gz'.\n",
      "2018-11-24 14:28:17.320 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file 'tmp/train-labels-idx1-ubyte.gz'.\n",
      "2018-11-24 14:28:17.328 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file 'tmp/t10k-images-idx3-ubyte.gz'.\n",
      "2018-11-24 14:28:17.394 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file 'tmp/t10k-labels-idx1-ubyte.gz'.\n",
      "2018-11-24 14:28:17.396 [scala-interpreter-1] INFO  MNIST Data Loader - Finished loading the MNIST dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataset\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mplatanios\u001b[39m.\u001b[32mtensorflow\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mimage\u001b[39m.\u001b[32mMNISTDataset\u001b[39m = \u001b[33mMNISTDataset\u001b[39m(\n",
       "  MNIST,\n",
       "  Tensor[UByte, [60000, 28, 28]],\n",
       "  Tensor[UByte, [60000]],\n",
       "  Tensor[UByte, [10000, 28, 28]],\n",
       "  Tensor[UByte, [10000]]\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataset = MNISTLoader.load(Paths.get(\"tmp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a few example images from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/klEQVQokd3QwUdEYRQF8CORFqUnxTAyZpmnRUSrpPkDxqzSomJItE7bkohoXctmk1nUKmlo0T6aZv2ikeJR7xE9psU5Xot5hm+++f6Bzuq6P2dxL/BfM7168io97I1YMnNYS0R+NcXTPiocfZBU68xH+f3OtGIgMriY8wCgZmIhoMKdcQDAQpiYWJHq2bj0k+rawAY5251WIuoxBwAYzvANqOSf4mVve34CrXJoNP2I4svzr0juTvUfOXkgkhRZH7I+AAAYvU11bvWyXFLt3GAa2/pmtOjorbF3j5X9hNx02E2qzobDvE+1Sw7DOjtVl+Gex9au940rxM7iwPwBiENs9OwBxWUAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAj0lEQVQokWNgGARg8SY8kke/COCUU/zwVwjOYUKTTOJF4qBLmjJ8+ovLVNsffzfi1JnEyvAQp3u2/P3CjEtO79/fYzgdVMbAsBanqXv+PxPFJSf17V8ZTo3r//6Wxil54+8CnHLVv/764pJj//r3Mk65DX//xuKSFP779wzO0In8+9cYp3N4Hl7mwilJPwAAsZIs9UmesMwAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABD0lEQVQokcWQTyhEYRTFf0+TxdSU5hXRLGxmmq1ZKVZKSUJibSVlJwsbZG+hLDWlrEVJb2ExKdNsSOyU1dSQPys9UTq3ZzMvvXnfmru63d937j3fgf+vvpmLe7uacrLcnUxS08WyR5JJ+hoDoCsBx2fhY31w7jCfFm5FZrUl573SYmi6HXH7fJXspej+xLakVq+b5a7N3t0IVk1a65hl4qYIlBoR1YNf6MVNsxCBF8HT2UM1TCqzGe97L6ByU+nZoLycXL8gq7ef1aV28HF8tTd8H4DPR5jscLZpGgZgIJROkkqCS28iAzCd9bznDreMHueDxhDMR6zsp2Io7YYmyXTupxjQX95p6bTQ7WJ/VT+UQGM8Zg9GjAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVQokc3PsUtCARAG8A9C7EVDtPSmXBrCQQh0DHJs6dHkUFPREM0GhQoNDdHYKjYlZCD0B0hIQS4NQg5BLYEiIRTxwCK+L4cafK9ra+im7/gddxzwz2pkuBnb22xPd2WMRdLbLYq8O5z4YbEiSYoke5mQRY/Fl1w2fpE9bas3HsQa1Zj9ilPiUsA8qel8551PBTHuU/dHLgB4vh5Ca/M3dfLRA1BmK2TAaGThirxdPfhgyngUk4t1kTy3DACKkpZ/w2eSjYRt6+pvNXliWvJNK9jlpYlVnjlwOybGXjUPoNR1LX1iCtGC/z5jo5e7JtfMm2WK7G+YBmdflcKcbX9YA+m1dXARlp6OAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7ElEQVQokc2Pv0sCcRiHH687FbKsG9REiAqc3ZsUQlzcHR1c3PwTXF2aG/wjpCHcgtajH3NLNDkEbgYqn3O4S677doGbz/J+eR8+7/t+YU+5e04DkK1HmlZY5zUHgP6obspLzgC4rzXMsa8aBo/lt2GvF7oIpaZxOZEOf+RLfOcR3gqAAyhWfwfPPzW2sEulm0dJT07YtgEoVuhm1iftoOfmv6LJ0zdJki9f8tWPHdT2tGW23ZkKa748WM57D3i3Ni3jM4DtAh2p+YcLyEWkZdgUx4lJZ6rZVVJy9U7BTRwb4V9pUtVHZbfErmwAi45MdMYv7/kAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36msess\u001b[39m: \u001b[32mSession\u001b[39m = org.platanios.tensorflow.api.core.client.Session@38fbcf85\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mshowImage\u001b[39m\n",
       "\u001b[36mrandomImages\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[\u001b[32mTensor\u001b[39m[\u001b[32mUByte\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]]\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sess = Session()\n",
    "def showImage(image: Tensor[UByte]): Unit = {\n",
    "  val exampleImage = tf.decodeRaw[Byte](tf.image.encodePng(image))\n",
    "  val png = sess.run(fetches = exampleImage)\n",
    "  Image.fromArray(png.entriesIterator.toArray, Image.PNG, width=Some(\"50\"))\n",
    "}\n",
    "\n",
    "val randomImages = for {\n",
    "  index <- (0 to 4).map(_ => Random.nextInt(dataset.testImages.shape(0)))\n",
    "  image = dataset.testImages(index).expandDims(-1)\n",
    "} yield image\n",
    "randomImages.foreach(showImage(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainImages\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = Dataset[TensorSlicesDataset]\n",
       "\u001b[36mtrainLabels\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]] = Dataset[TensorSlicesDataset]\n",
       "\u001b[36mtrainData\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m])] = Dataset[TensorSlicesDataset/Zip/Repeat/Shuffle/Batch/Prefetch]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Load and batch data using pre-fetching.\n",
    "val trainImages = tf.data.datasetFromTensorSlices(dataset.trainImages.toFloat)\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataset.trainLabels.toLong)\n",
    "val trainData =\n",
    "  trainImages.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(256)\n",
    "      .prefetch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minput\u001b[39m: \u001b[32mInput\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = org.platanios.tensorflow.api.learn.layers.Input@72322be\n",
       "\u001b[36mtrainInput\u001b[39m: \u001b[32mInput\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]] = org.platanios.tensorflow.api.learn.layers.Input@16bfec77\n",
       "\u001b[36mlayer\u001b[39m: \u001b[32mCompose\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "  \u001b[33mCompose\u001b[39m(\n",
       "    \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "    \u001b[33mCompose\u001b[39m(\n",
       "      \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "      \u001b[33mCompose\u001b[39m(\n",
       "        \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "        \u001b[33mCompose\u001b[39m(\n",
       "          \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "          \u001b[33mCompose\u001b[39m(\n",
       "            \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "            \u001b[33mCompose\u001b[39m(\n",
       "              \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "              \u001b[33mFlatten\u001b[39m(\u001b[32m\"Input/Flatten\"\u001b[39m),\n",
       "              \u001b[33mLinear\u001b[39m(\n",
       "                \u001b[32m\"Layer_0\"\u001b[39m,\n",
       "                \u001b[32m128\u001b[39m,\n",
       "                true,\n",
       "                \u001b[33mRandomNormalInitializer\u001b[39m(\n",
       "                  Tensor[Float, []],\n",
       "                  Tensor[Float, []],\n",
       "                  \u001b[32mNone\u001b[39m\n",
       "                ),\n",
       "                \u001b[33mRandomNormalInitializer\u001b[39m(\n",
       "                  Tensor[Float, []],\n",
       "                  Tensor[Float, []],\n",
       "                  \u001b[32mNone\u001b[39m\n",
       "                )\n",
       "              )\n",
       "            ),\n",
       "            \u001b[33mReLU\u001b[39m(\u001b[32m\"Layer_0/Activation\"\u001b[39m, \u001b[32m0.1F\u001b[39m)\n",
       "          ),\n",
       "          \u001b[33mLinear\u001b[39m(\n",
       "            \u001b[32m\"Layer_1\"\u001b[39m,\n",
       "            \u001b[32m64\u001b[39m,\n",
       "            true,\n",
       "            \u001b[33mRandomNormalInitializer\u001b[39m(Tensor[Float, []], Tensor[Float, []], \u001b[32mNone\u001b[39m),\n",
       "            \u001b[33mRandomNormalInitializer\u001b[39m(Tensor[Float, []], Tensor[Float, []], \u001b[32mNone\u001b[39m)\n",
       "...\n",
       "\u001b[36mloss\u001b[39m: \u001b[32mCompose\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Loss\"\u001b[39m,\n",
       "  \u001b[33mSparseSoftmaxCrossEntropy\u001b[39m(\u001b[32m\"Loss\"\u001b[39m),\n",
       "  \u001b[33mMean\u001b[39m(\u001b[32m\"Loss/Mean\"\u001b[39m, \u001b[32mnull\u001b[39m, false)\n",
       ")\n",
       "\u001b[36moptimizer\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mtraining\u001b[39m.\u001b[32moptimizers\u001b[39m.\u001b[32mGradientDescent\u001b[39m = org.platanios.tensorflow.api.ops.training.optimizers.GradientDescent@574aa91c\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mSupervisedTrainableModel\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mFloat\u001b[39m] = org.platanios.tensorflow.api.learn.Model$$anon$1@c08c9fe"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create the MLP model.\n",
    "val input = Input(FLOAT32, Shape(-1, 28, 28))\n",
    "val trainInput = Input(INT64, Shape(-1))\n",
    "val layer = Flatten[Float](\"Input/Flatten\") >>\n",
    "    Linear[Float](\"Layer_0\", 128) >> ReLU[Float](\"Layer_0/Activation\", 0.1f) >>\n",
    "    Linear[Float](\"Layer_1\", 64) >> ReLU[Float](\"Layer_1/Activation\", 0.1f) >>\n",
    "    Linear[Float](\"Layer_2\", 32) >> ReLU[Float](\"Layer_2/Activation\", 0.1f) >>\n",
    "    Linear[Float](\"OutputLayer\", 10)\n",
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\")\n",
    "val optimizer = tf.train.GradientDescent(1e-6f)\n",
    "val model = Model.simpleSupervised(input, trainInput, layer, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 14:38:34.854 [scala-interpreter-1] INFO  Variables / Saver - Restoring parameters from '/tmp/summaries/model.ckpt-1000'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.hooks._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.config.TensorBoardConfig\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mloss\u001b[39m: \u001b[32mCompose\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Loss\"\u001b[39m,\n",
       "  \u001b[33mCompose\u001b[39m(\n",
       "    \u001b[32m\"Loss\"\u001b[39m,\n",
       "    \u001b[33mSparseSoftmaxCrossEntropy\u001b[39m(\u001b[32m\"Loss\"\u001b[39m),\n",
       "    \u001b[33mMean\u001b[39m(\u001b[32m\"Loss/Mean\"\u001b[39m, \u001b[32mnull\u001b[39m, false)\n",
       "  ),\n",
       "  \u001b[33mScalarSummary\u001b[39m(\n",
       "    \u001b[32m\"Loss\"\u001b[39m,\n",
       "    \u001b[32m\"Loss\"\u001b[39m,\n",
       "    \u001b[32mnull\u001b[39m,\n",
       "    \u001b[33mSet\u001b[39m(org.platanios.tensorflow.api.core.Graph$Keys$SUMMARIES$@17ccd9e0)\n",
       "  )\n",
       ")\n",
       "\u001b[36msummariesDir\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mfile\u001b[39m.\u001b[32mPath\u001b[39m = /tmp/summaries\n",
       "\u001b[36mestimator\u001b[39m: \u001b[32mInMemoryEstimator\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mFloat\u001b[39m, (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]))] = org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator@39294572"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.platanios.tensorflow.api.learn.hooks._\n",
    "import org.platanios.tensorflow.api.config.TensorBoardConfig\n",
    "\n",
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\") >>\n",
    "    ScalarSummary(name = \"Loss\", tag = \"Loss\")\n",
    "val summariesDir = Paths.get(\"/tmp/summaries\")\n",
    "val estimator = InMemoryEstimator(\n",
    "  modelFunction = model,\n",
    "  configurationBase = Configuration(Some(summariesDir)),\n",
    "  trainHooks = Set(\n",
    "    SummarySaver(summariesDir, StepHookTrigger(100)),\n",
    "    CheckpointSaver(summariesDir, StepHookTrigger(1000))),\n",
    "  tensorBoardConfig = TensorBoardConfig(summariesDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 14:38:59.519 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 2000.\n",
      "2018-11-24 14:38:59.520 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-2000'.\n",
      "2018-11-24 14:39:00.924 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-2000'.\n",
      "2018-11-24 14:39:05.495 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 3000.\n",
      "2018-11-24 14:39:05.496 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-3000'.\n",
      "2018-11-24 14:39:06.369 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-3000'.\n",
      "2018-11-24 14:39:09.883 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 4000.\n",
      "2018-11-24 14:39:09.883 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-4000'.\n",
      "2018-11-24 14:39:10.639 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-4000'.\n",
      "2018-11-24 14:39:13.802 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 5000.\n",
      "2018-11-24 14:39:13.803 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-5000'.\n",
      "2018-11-24 14:39:14.542 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-5000'.\n",
      "2018-11-24 14:39:18.008 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 6000.\n",
      "2018-11-24 14:39:18.009 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-6000'.\n",
      "2018-11-24 14:39:19.035 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-6000'.\n",
      "2018-11-24 14:39:22.608 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 7000.\n",
      "2018-11-24 14:39:22.608 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-7000'.\n",
      "2018-11-24 14:39:23.341 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-7000'.\n",
      "2018-11-24 14:39:27.112 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 8000.\n",
      "2018-11-24 14:39:27.113 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-8000'.\n",
      "2018-11-24 14:39:27.896 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-8000'.\n",
      "2018-11-24 14:39:31.346 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 9000.\n",
      "2018-11-24 14:39:31.346 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-9000'.\n",
      "2018-11-24 14:39:32.548 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-9000'.\n",
      "2018-11-24 14:39:35.867 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 10000.\n",
      "2018-11-24 14:39:35.868 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-10000'.\n",
      "2018-11-24 14:39:36.636 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-10000'.\n",
      "2018-11-24 14:39:39.806 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 11000.\n",
      "2018-11-24 14:39:39.806 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/tmp/summaries/model.ckpt-11000'.\n",
      "2018-11-24 14:39:40.704 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/tmp/summaries/model.ckpt-11000'.\n"
     ]
    }
   ],
   "source": [
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVQokWNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kI4JvP8AAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 7"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVQokWNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhxCiBkuF8LAcGPpa3Wht4cx9Jn8+ntJgYeB7dzfHkxDfX9fkmRgYKj68dcRi5XyQgwMDAwX/2KVZGBgYGAo/f73GBcOOZ/vf5/bI/GZUFzFxrDyIA6NG779nc+DQ07y1d+Xyrhcc+zv315ccn4//u7FZajwCTwa2/7+XYtLI8OPv38l0cVYkNhCvxkYGD7+ZuVnECxkYPhb/g1Z8hIDAwPD6ufi4RDui1Z4Sljnj1D15x/DpjMMR44jkkkZKwODdjgDw7wHDOuu43LZAAMAWllQaMgkNq4AAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 2"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAjklEQVQokWNgoD9gRhdQe/3uFIzNhC5p+O8pbqPaP+KW0/0yDcFBN1adayVunafuc+OUU/h3A4mHZqw9w2vckroMXThNtXx7lgOnTmehGz9wSur/X4PTVIkX11H4KDoTxE7glpRneI/TVIYn/5xw6rQVx62PofffWdS4R9LJ5cWw5i8ujazHNnDhMZdOAABQEyD7KdJU1AAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 1"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA8klEQVQokcXQMUtCURgG4NdjQuiaQ8u9gYg/wEEI0jEd/CEhCv6AQEdBRBCa+wM1OtXUov2BKDQo4gqu0vTyosPtlp5zW/Wb3nOecz74PuDAlbnRs/8f5kk1ts5mK2dvrcfJv9i6PgcS36fHHzFNRZIiZ0XXxmtJWr5LcqwyF8lRvdwhryw7W1Cc9dKAH3DVTjlTPJwAAJoUczZOvTD6kwh/5zSm9BmmhDGmu/OzT0bRbfsaYbayoAIvHock5xdhPrJGGhcAvDztXr5JtdqXtFbMhtpktFuObPSDHwwec2kbUR6E2HAEAFC9591l1YvHvdUGJJOAOqgBKmsAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 0"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVQokWNgGLzA6AGU4SYLZTAhJN3ZoQy/bgxJFi8Y64wWN7qko+V8KEtIiwvNRt03N3mgzAN/RNEkV3w3hWn8/xdNMuTTZRiz9+9eVlTJlX+yoCyFF7+cUOX4H/6BMdv+wM2AupZdegVMRJnhCppzOM9cFIKwxP7+zYaJskCo73eDt/YxMDDoKMv/Z/iPppNBc9XXP3/+/Hnx/PefP5wwQUa4tKEyAwPDGoaF0TDTsID6P3900exEAEZGhss4Jf8jOYcJXZKD4QdOKxlevMnHLbnZCbcclQAA/k48HXOpiTkAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 4"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoklEQVQokWNgGGSAGV3A98abc/9xKBZ+/O8fJy6TAv/9W8qIQ4799L9/nrg0mv779wvBY0IzlYFhFy6NDEf+/TDAJWf1799bJC6qsaYMDNNxmrr43zsZXHI2f/7dR+ajGCvMxLAbn6mmuORk/vy7hCKAbKwVE8NGnKZm/nslglOnG8Ojj7gkWVUYfvzGJfnvNMMdVHuQksn/04JnT+N0EBUBABoMMeI4qlfqAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 1"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA30lEQVQokWNgGGSAGc4S26p29wOUze92/x+yKsHXv1bC2Px3Pqoiy4ns/TsZzun+m4JivNvfv6Iwtva/tbzIcmIz/ybA5Z7/i0HRuPj/GW4YO+PfPFRHL/q7iRXC4mx++xcmygJjeO/6MJ2BgcHewYJhDapGBuMnf//++/v3799/f//eVkbTeVbXwKP09UIGhsUXGY7dZcABlP6dE8Ulx7DgrytOudB/H41wSs77txSnHMPzL7g1Zvx7gVvjhb9zGXjl4FwmNOm/0fubcer893eWLA5J230N4my4baUSAAD1ME6TqA5rBAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 4"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVQokWNgGKqAb+pBVlxy0Q/+/hXGISfz+t/fv8uEsEtO+Pvv79+/74rZsMjJf/x7Yeffv3+fS2CR9P93kIEj6fa//ycRJjPBGOz/+xl+zLv9//+3X5iSkQzeDAwMJgwMJ75gGhv294JG6LLfb/+90cKUFHr399/fvztVbvydgcVFLh/+/5vIwdD2774yNtl5fTwMDJzr/y7EIgkFEX8fwTzDjCF5Td3y+0GcWg2+/lXDpZPhxU83qc1/cGkVvfVPD7eb5P4txS3JsOsLlmCCAb77fni0EgEARxFUnCmnzVwAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7UlEQVQokWNgoD9gxhARVJeQ+FkpyvoSU7H3zJt///69/u3vX3QZ5b4vf/7CAAMDAwuypEw+hL5xFULDJUUKjuz49fEr964rJ89//4pqIve5v34MDAoMckyY7mDb+LeFC4eHeFr/vuTHIccQ8/e+DBZhiBVWDOefYJGEhNB8LkWWTy8wJBkZGBgYGP7/Y2D4N+OE3J2rDNrH0c3o/osAL1agG256695vmOyfGkzbnT1OQGXXY/NQxd+fM4yX4JA0+vv3754/f/9OwSbJufzv379/f63nxibJIL7l+d+7DVilGBgYGGKniuGUow8AAK1edM1OQ1sFAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 6"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBElEQVQokd3QsS8DcRjG8UcOPUFiINLNYGgj2M7QpTGISSIxWRkMFomIGESCwWJ1XTtYDP4Ag60xoqNBqjW0IWlPQ/Tc9wyWa/P7/QOe7c3nfYb3lf5N+rqm6fHVPH7pybA46zcA6JQvBntortCE6uVpeMdrZavbCg24OXel20zp8zmaSJB7GFE/Gpakx5klIInLH9Q8SXKmdisBcXFAkvr/0IkULqxl9JXNvk1K9ZMw0Ry6bkcxhAD8XKV77hzbz72/pOY9Sf5B0/iTIrQ2HCNprwPrZtJmAOWU2bwWBDlL8RjaeYuNfoNvsZEa3LsWXIlh0WJ6gDObqRrX01bcibetZsovhERycoR1WsYAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mimages\u001b[39m: \u001b[32mTensor\u001b[39m[\u001b[32mUByte\u001b[39m] = Tensor[UByte, [10, 28, 28]]\n",
       "\u001b[36mresult\u001b[39m: \u001b[32mTensor\u001b[39m[\u001b[32mFloat\u001b[39m] = Tensor[Float, [10, 10]]\n",
       "\u001b[36mpredictedClasses\u001b[39m: \u001b[32mTensor\u001b[39m[\u001b[32mLong\u001b[39m] = Tensor[Long, [10]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val images = dataset.testImages(0::10)\n",
    "val result = estimator.infer(() => images.toFloat)\n",
    "val predictedClasses = result.argmax(1)\n",
    "for (i <- 0 until images.shape(0)) {\n",
    "    showImage(images(i).expandDims(-1))\n",
    "    print(\"predicted class: \")\n",
    "    print(predictedClasses(i).scalar)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
